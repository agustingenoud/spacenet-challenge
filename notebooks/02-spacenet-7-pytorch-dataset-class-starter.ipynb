{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029631,
     "end_time": "2020-12-03T20:04:36.260622",
     "exception": false,
     "start_time": "2020-12-03T20:04:36.230991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027009,
     "end_time": "2020-12-03T20:04:36.316619",
     "exception": false,
     "start_time": "2020-12-03T20:04:36.289610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In our [previous notebook](https://www.kaggle.com/amerii/spacenet-7-helper-functions) we programmed a few helper functions that made our lives much easier. Let's see how we are going to use those functions now to create our dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:36.388289Z",
     "iopub.status.busy": "2020-12-03T20:04:36.387440Z",
     "iopub.status.idle": "2020-12-03T20:04:41.014062Z",
     "shell.execute_reply": "2020-12-03T20:04:41.013178Z"
    },
    "papermill": {
     "duration": 4.670103,
     "end_time": "2020-12-03T20:04:41.014206",
     "exception": false,
     "start_time": "2020-12-03T20:04:36.344103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import rasterio as rio\n",
    "from rasterio import features\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import geopandas as gpd\n",
    "from descartes import PolygonPatch\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import imgaug\n",
    "import random\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:41.077040Z",
     "iopub.status.busy": "2020-12-03T20:04:41.076251Z",
     "iopub.status.idle": "2020-12-03T20:04:41.079834Z",
     "shell.execute_reply": "2020-12-03T20:04:41.079049Z"
    },
    "papermill": {
     "duration": 0.037876,
     "end_time": "2020-12-03T20:04:41.079997",
     "exception": false,
     "start_time": "2020-12-03T20:04:41.042121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "im_path = Path('../data/train/L15-0331E-1257N_1327_3160_13/images/global_monthly_2018_01_mosaic_L15-0331E-1257N_1327_3160_13.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:41.229263Z",
     "iopub.status.busy": "2020-12-03T20:04:41.228483Z",
     "iopub.status.idle": "2020-12-03T20:04:41.400485Z",
     "shell.execute_reply": "2020-12-03T20:04:41.399799Z"
    },
    "papermill": {
     "duration": 0.292424,
     "end_time": "2020-12-03T20:04:41.400651",
     "exception": false,
     "start_time": "2020-12-03T20:04:41.108227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rio.open(im_path) as r:\n",
    "    print(r.read().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true,
    "papermill": {
     "duration": 0.028967,
     "end_time": "2020-12-03T20:04:41.459578",
     "exception": false,
     "start_time": "2020-12-03T20:04:41.430611",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# [Dataset class](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class)\n",
    "\n",
    "## (Work in Progress)\n",
    "\n",
    "`torch.utils.data.Dataset` is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods:\n",
    "\n",
    "* `__len__` so that `len(dataset)` returns the size of the dataset.\n",
    "* `__getitem__` to support the indexing such that `dataset[i]` can be used to get *ith* sample\n",
    "\n",
    "Letâ€™s create a dataset class for our dataset. We will read the [csv that we created in our previous notebook](https://www.kaggle.com/amerii/spacenet-7-directory-metadata-extraction), in `__init__` but leave the reading of images to `__getitem__`. This is memory efficient because all the images are not stored in the memory at once but read as required.\n",
    "\n",
    "### Retrieving the Satellite Image Samples\n",
    "\n",
    "The sample that we are going to retrieve from our dataset will be retrieved in one of the 2 following ways:\n",
    "\n",
    "* image_diff: The concatenated array of image1 and image2 that will be fed into our neural network\n",
    "* date1 and date2: The dates that each of the satellite images were captured on\n",
    "* im_dir: The parent image directory name\n",
    "* mask_diff: The rasterized image of the change between the two ground truth polygons from both images\n",
    "* blank_label: Boolean, indicating whether the output mask has a change or not. \n",
    "\n",
    "\n",
    "\n",
    "```sample = {'image_diff':image_diff_dict['chip'][chip_idx],\n",
    "             'mask_diff':mask_diff_dict['chip'][chip_idx]\n",
    "             'date1':date1,'date2':date2,\n",
    "             'im_dir':img1_path.parent.parent,\n",
    "             'blank_label':mask_diff_dict['blank'][chip_idx]}```\n",
    "\n",
    "Our dataset will take an optional argument `transform` so that any required processing can be applied on the sample.\n",
    "\n",
    "Our dataset will also take another optional argument `chip_dimension` which specifies the dimensions of the output chips incase we want to segment our satellite image into smaller chips.\n",
    "The chip dimension will be fed into our `ChipGenerator` Class, which creates chips out of the input satellite image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:41.525383Z",
     "iopub.status.busy": "2020-12-03T20:04:41.524171Z",
     "iopub.status.idle": "2020-12-03T20:04:41.527778Z",
     "shell.execute_reply": "2020-12-03T20:04:41.527134Z"
    },
    "papermill": {
     "duration": 0.039755,
     "end_time": "2020-12-03T20:04:41.527915",
     "exception": false,
     "start_time": "2020-12-03T20:04:41.488160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=0):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    imgaug.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:41.600641Z",
     "iopub.status.busy": "2020-12-03T20:04:41.599483Z",
     "iopub.status.idle": "2020-12-03T20:04:41.603690Z",
     "shell.execute_reply": "2020-12-03T20:04:41.604376Z"
    },
    "papermill": {
     "duration": 0.044479,
     "end_time": "2020-12-03T20:04:41.604554",
     "exception": false,
     "start_time": "2020-12-03T20:04:41.560075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.randint(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:41.683961Z",
     "iopub.status.busy": "2020-12-03T20:04:41.673169Z",
     "iopub.status.idle": "2020-12-03T20:04:41.734806Z",
     "shell.execute_reply": "2020-12-03T20:04:41.734018Z"
    },
    "papermill": {
     "duration": 0.100937,
     "end_time": "2020-12-03T20:04:41.734950",
     "exception": false,
     "start_time": "2020-12-03T20:04:41.634013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiTemporalSatelliteDataset(Dataset):\n",
    "    \"\"\"SpaceNet 7 Multi-Temporal Satellite Imagery Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self,csv_file, root_dir, no_udm=True, transform=None, chip_dimension=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (Path): Path to the csv file with annotations\n",
    "            root_dir (Path): Parent directory containing all other directories.\n",
    "            no_udm (bool): Specifies whether the dataset will load UDM images or not.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            chip_dimension (int, optional): Specifies the dimensions of the chip being generated.\n",
    "        \"\"\"\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.no_udm = no_udm\n",
    "        self.transform = transform\n",
    "        self.idx_combinations = self.__get_all_idx_combinations()\n",
    "        self.chip_dimension = chip_dimension\n",
    "        if self.chip_dimension is not None:\n",
    "            self.chip_generator = self.__ChipGenerator(chip_dimension = self.chip_dimension)\n",
    "            # this will be replaced later with an abstracted version\n",
    "            # returns number of chips per image assuming all images are 1024\n",
    "            self.n_chips = ((1024 - 1) // self.chip_dimension + 1)**2\n",
    "            \n",
    "    def __len__(self):\n",
    "        if self.chip_dimension is not None:\n",
    "            return len(self.idx_combinations)*self.n_chips\n",
    "        else:\n",
    "            return len(self.idx_combinations)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if self.chip_dimension is not None:\n",
    "            raster_idx = idx//self.n_chips\n",
    "            chip_idx = idx%self.n_chips\n",
    "        else:\n",
    "            raster_idx = idx\n",
    "            \n",
    "        if torch.is_tensor(raster_idx):\n",
    "            raster_idx = raster_idx.tolist()\n",
    "        # get the indices of the 2 images\n",
    "        idx1,idx2 = self.idx_combinations[raster_idx]\n",
    "        # paths where the images are stored\n",
    "        img1_path = self.root_dir/self.annotations.loc[idx1,'images_masked']\n",
    "        img2_path = self.root_dir/self.annotations.loc[idx2,'images_masked']\n",
    "        # paths where the corresponding true building footprints \n",
    "        labels1_path = self.root_dir/self.annotations.loc[idx1,'labels_match_pix']\n",
    "        labels2_path = self.root_dir/self.annotations.loc[idx2,'labels_match_pix']\n",
    "        # read rasters using imported rasterio library\n",
    "        with rio.open(img1_path) as r1, rio.open(img2_path) as r2:\n",
    "            raster1 = r1.read()[0:3]  \n",
    "            raster2 = r2.read()[0:3]\n",
    "        # get the concatenated array of the 2 images that will be fed into the neural_net\n",
    "        raster_diff = np.concatenate((raster1,raster2),axis=0)\n",
    "        # get the dates for the images\n",
    "        date1 = tuple(self.annotations.loc[idx1,['month','year']])\n",
    "        date2 = tuple(self.annotations.loc[idx2,['month','year']])\n",
    "        # read geojson files for each of the satellite images into a geodataframe\n",
    "        gdf1 = gpd.read_file(labels1_path).set_index('Id').sort_index()\n",
    "        gdf2 = gpd.read_file(labels2_path).set_index('Id').sort_index()\n",
    "        # get the change between the 2 satellite images by comparing their polygons\n",
    "        gdf_diff = self.__geo_difference(labels1_path,labels2_path)\n",
    "        # get the corresponding rasterized image of the geodataframes\n",
    "        mask_diff = self.__rasterize_gdf(gdf_diff,out_shape=raster1.shape[1:3])\n",
    "        \n",
    "        if self.chip_dimension:\n",
    "            raster_diff_dict = self.chip_generator(raster_diff)\n",
    "            mask_diff_dict = self.chip_generator(mask_diff)\n",
    "\n",
    "            sample = {'raster_diff':raster_diff_dict['chip'][chip_idx],'date1':date1,'date2':date2,\n",
    "          'mask_diff':mask_diff_dict['chip'][chip_idx],'im_dir':str(img1_path.parent.parent),'blank_label':mask_diff_dict['blank'][chip_idx]}\n",
    "        \n",
    "        else:\n",
    "            sample = {'raster_diff':raster_diff,'date1':date1,'date2':date2,'mask_diff':mask_diff,'im_dir':str(img1_path.parent.parent)}\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            # get the individual images and mask from the output sample\n",
    "            raster1 = np.moveaxis(np.uint8(sample['raster_diff'][:3]),0,-1)\n",
    "            raster2 = np.moveaxis(np.uint8(sample['raster_diff'][3:6]),0,-1)\n",
    "            mask = np.moveaxis(np.uint8(sample['mask_diff']),0,-1)\n",
    "            \n",
    "            seed = random.randint(0,1000)\n",
    "            set_seed(seed)\n",
    "            \n",
    "            # apply transform on first image and mask\n",
    "            transformed = self.transform(image=raster1,mask=mask)\n",
    "            raster1 = transformed['image']\n",
    "            mask_diff = transformed['mask']\n",
    "            \n",
    "            set_seed(seed)\n",
    "            \n",
    "            # apply transform on second image\n",
    "            raster2 = self.transform(image=raster2)['image']\n",
    "            # concatenate input images\n",
    "            raster_diff = torch.cat((raster1,raster2))\n",
    "            # update sample dictionary paramters after transformation\n",
    "            if not isinstance(raster_diff,np.ndarray):\n",
    "                sample['raster_diff'] = raster_diff\n",
    "                mask_diff = mask_diff.permute(2,0,1)\n",
    "                sample['mask_diff'] = mask_diff\n",
    "            else:\n",
    "                sample['raster_diff'] = raster_diff\n",
    "                mask_diff = np.moveaxis(mask_diff,-1,0)\n",
    "                sample['mask_diff'] = mask_diff\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    def __get_all_idx_combinations(self):\n",
    "        all_combinations = []\n",
    "        # group by satellite image location\n",
    "        location_groups = self.annotations.groupby('image_dir_name')\n",
    "        # loop through the groups and get the different index combinations\n",
    "        for i,location in enumerate(location_groups):\n",
    "            # get the dataframe in the group\n",
    "            loc_frame = location[1]\n",
    "            # make sure that list does not contain images with unidentified masks\n",
    "            condition = (loc_frame['has_udm'] == False)\n",
    "            # return a list of the indices in the location dataframe\n",
    "            l = list(loc_frame[condition].index)\n",
    "            # use itertools to get all the different combinations between 2 in the list\n",
    "            combinations = list(itertools.combinations(l,2))\n",
    "            all_combinations.extend(combinations)\n",
    "        return all_combinations\n",
    "        \n",
    "    def __geo_difference(self,geojson1,geojson2):\n",
    "        # read geojson into geodataframes\n",
    "        gdf1 = gpd.read_file(geojson1).set_index('Id').sort_index()\n",
    "        gdf2 = gpd.read_file(geojson2).set_index('Id').sort_index()\n",
    "\n",
    "        # get geodataframe lengths\n",
    "        len_1 = len(gdf1)\n",
    "        len_2 = len(gdf2)\n",
    "        # check which gdf is longer\n",
    "        len_diff = abs(len_2-len_1)\n",
    "\n",
    "        if len_2 > len_1:\n",
    "            start_index = len_2-len_diff\n",
    "            diff_gdf = gdf2.iloc[start_index:].copy()\n",
    "        else:\n",
    "            start_index = len_1-len_diff\n",
    "            diff_gdf = gdf1.iloc[start_index:].copy()\n",
    "\n",
    "        # reset the index\n",
    "        diff_gdf.reset_index(inplace=True,drop=True)\n",
    "\n",
    "        return diff_gdf\n",
    "\n",
    "    \n",
    "    def __rasterize_gdf(self,gdf,out_shape):\n",
    "        # if geodataframe is empty return empty mask\n",
    "        if len(gdf)==0:\n",
    "            return np.zeros((1,*out_shape))\n",
    "            \n",
    "        mask = features.rasterize(((polygon, 255) for polygon in gdf['geometry']),out_shape=out_shape)\n",
    "        \n",
    "        return np.expand_dims(mask,axis=0)\n",
    "    \n",
    "    class __ChipGenerator():   \n",
    "        def __init__(self, chip_dimension=256,return_raster=False):  \n",
    "            self.chip_dimension = chip_dimension\n",
    "            self.return_raster = return_raster\n",
    "            self.chip_dict = {'chip':[],'x':[],'y':[], 'blank':[]}\n",
    "\n",
    "        def __call__(self,raster):\n",
    "            np_array = self.__read_raster(raster)\n",
    "            # get number of chips per colomn\n",
    "            n_rows = (np_array.shape[1] - 1) // self.chip_dimension + 1\n",
    "            # get number of chips per row\n",
    "            n_cols = (np_array.shape[2] - 1) // self.chip_dimension + 1\n",
    "            # segment image into chips and return dict of chips and metadata\n",
    "            chip_dict = {'chip':[],'x':[],'y':[], 'blank':[]}\n",
    "\n",
    "            for r in range(n_rows):\n",
    "                for c in range(n_cols):\n",
    "                    start_r_idx = r*self.chip_dimension\n",
    "                    end_r_idx = start_r_idx + self.chip_dimension\n",
    "\n",
    "                    start_c_idx = c*self.chip_dimension\n",
    "                    end_c_idx = start_c_idx + self.chip_dimension\n",
    "                    \n",
    "                    chip = np_array[:,start_r_idx:end_r_idx,start_c_idx:end_c_idx]\n",
    "\n",
    "                    chip_dict['chip'].append(chip)\n",
    "                    chip_dict['x'].append(start_r_idx)\n",
    "                    chip_dict['y'].append(start_c_idx)\n",
    "                    \n",
    "                    # Check if the chip is an empty chip\n",
    "                    if chip.mean() == 0 and chip.sum() == 0:\n",
    "                        chip_dict['blank'].append(1)\n",
    "                    else:\n",
    "                        chip_dict['blank'].append(0)\n",
    "\n",
    "            return chip_dict\n",
    "\n",
    "        def __read_raster(self,raster):\n",
    "            # check whether raster is a path or array\n",
    "            if isinstance(raster,(pathlib.PurePath,str)):\n",
    "                    with rio.open(raster) as r:\n",
    "                        # convert raster into np array\n",
    "                        np_array = r.read()\n",
    "                    return np_array\n",
    "\n",
    "            elif isinstance(raster,np.ndarray):\n",
    "                return raster\n",
    "            else:\n",
    "                raise ValueError(f\"Expected Path or Numpy array received: {type(raster)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:41.813153Z",
     "iopub.status.busy": "2020-12-03T20:04:41.812077Z",
     "iopub.status.idle": "2020-12-03T20:04:41.815004Z",
     "shell.execute_reply": "2020-12-03T20:04:41.815573Z"
    },
    "papermill": {
     "duration": 0.051557,
     "end_time": "2020-12-03T20:04:41.815738",
     "exception": false,
     "start_time": "2020-12-03T20:04:41.764181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' ToDo:\n",
    "Need to update function below to make it more similar to torchvision.utils.make_grid() method\n",
    "The final output will be 3 images:\n",
    "The stacked before images\n",
    "The stacked after images\n",
    "The stacked difference images\n",
    "'''\n",
    "def plot_sample(d,dpi=300,show=True):\n",
    "    # convert torch tensor to numpy array\n",
    "    if isinstance(d['raster_diff'],torch.Tensor):\n",
    "        raster_diff = d['raster_diff'].numpy()\n",
    "        mask_diff = d['mask_diff'].numpy()\n",
    "    else:\n",
    "        raster_diff = d['raster_diff']\n",
    "        mask_diff = d['mask_diff']\n",
    "        \n",
    "    # make sure channels are in the correct order for plotting\n",
    "    if d['raster_diff'].shape[0] <= 6:\n",
    "        image1 = np.moveaxis(raster_diff[0:3],0,-1)\n",
    "        image2 = np.moveaxis(raster_diff[3:6],0,-1)\n",
    "        mask_diff = np.moveaxis(mask_diff,0,-1).squeeze()\n",
    "    else:\n",
    "        image1 = d['raster_diff'][0:3]\n",
    "        image2 = d['raster_diff'][3:6]\n",
    "        \n",
    "    images = [image1,image2,mask_diff]\n",
    "    \n",
    "    mpl.rcParams['figure.dpi'] = dpi\n",
    "    ncols = 3\n",
    "    fig,axs = plt.subplots(1,ncols,figsize=(10,10))\n",
    "    fig.tight_layout()\n",
    "    plt.tick_params(axis = 'both', which = None, bottom = None, top = None) \n",
    "    \n",
    "    date1 = d['date1']\n",
    "    date2 = d['date2']\n",
    "    titles = [d['date1'],d['date2'],'difference']\n",
    "    \n",
    "    \n",
    "\n",
    "    for n in range(ncols):\n",
    "        axs[n].set_title(titles[n])\n",
    "        axs[n].imshow(images[n])\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        return axs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030431,
     "end_time": "2020-12-03T20:04:41.876224",
     "exception": false,
     "start_time": "2020-12-03T20:04:41.845793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Paths to Directories and Files\n",
    "The csv file that we are going to be using to load the data into our dataset was [created in one of our previous notebooks](https://www.kaggle.com/amerii/spacenet-7-directory-metadata-extraction). The data is formatted in such a way that we can easily access the files we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:41.942080Z",
     "iopub.status.busy": "2020-12-03T20:04:41.941300Z",
     "iopub.status.idle": "2020-12-03T20:04:41.944084Z",
     "shell.execute_reply": "2020-12-03T20:04:41.943361Z"
    },
    "papermill": {
     "duration": 0.038203,
     "end_time": "2020-12-03T20:04:41.944218",
     "exception": false,
     "start_time": "2020-12-03T20:04:41.906015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = Path('..data/train')\n",
    "csv_file = Path('../input/spacenet-7-directory-metadata-extraction/output_csvs/df_train_untidy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:42.013883Z",
     "iopub.status.busy": "2020-12-03T20:04:42.013048Z",
     "iopub.status.idle": "2020-12-03T20:04:42.058426Z",
     "shell.execute_reply": "2020-12-03T20:04:42.057674Z"
    },
    "papermill": {
     "duration": 0.084496,
     "end_time": "2020-12-03T20:04:42.058582",
     "exception": false,
     "start_time": "2020-12-03T20:04:41.974086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:42.141909Z",
     "iopub.status.busy": "2020-12-03T20:04:42.140862Z",
     "iopub.status.idle": "2020-12-03T20:04:42.155760Z",
     "shell.execute_reply": "2020-12-03T20:04:42.155033Z"
    },
    "papermill": {
     "duration": 0.06567,
     "end_time": "2020-12-03T20:04:42.155882",
     "exception": false,
     "start_time": "2020-12-03T20:04:42.090212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030425,
     "end_time": "2020-12-03T20:04:42.217119",
     "exception": false,
     "start_time": "2020-12-03T20:04:42.186694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utilizing our Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:42.285587Z",
     "iopub.status.busy": "2020-12-03T20:04:42.284754Z",
     "iopub.status.idle": "2020-12-03T20:04:42.386846Z",
     "shell.execute_reply": "2020-12-03T20:04:42.386104Z"
    },
    "papermill": {
     "duration": 0.138885,
     "end_time": "2020-12-03T20:04:42.386995",
     "exception": false,
     "start_time": "2020-12-03T20:04:42.248110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = MultiTemporalSatelliteDataset(root_dir=root_dir,csv_file=csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:42.457145Z",
     "iopub.status.busy": "2020-12-03T20:04:42.456343Z",
     "iopub.status.idle": "2020-12-03T20:04:46.105029Z",
     "shell.execute_reply": "2020-12-03T20:04:46.105664Z"
    },
    "papermill": {
     "duration": 3.687713,
     "end_time": "2020-12-03T20:04:46.105835",
     "exception": false,
     "start_time": "2020-12-03T20:04:42.418122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_sample(train_set[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:46.314107Z",
     "iopub.status.busy": "2020-12-03T20:04:46.312840Z",
     "iopub.status.idle": "2020-12-03T20:04:46.391869Z",
     "shell.execute_reply": "2020-12-03T20:04:46.391028Z"
    },
    "papermill": {
     "duration": 0.185026,
     "end_time": "2020-12-03T20:04:46.392025",
     "exception": false,
     "start_time": "2020-12-03T20:04:46.206999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set_512 = MultiTemporalSatelliteDataset(root_dir=root_dir,csv_file=csv_file,chip_dimension=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:46.594480Z",
     "iopub.status.busy": "2020-12-03T20:04:46.593352Z",
     "iopub.status.idle": "2020-12-03T20:04:49.534546Z",
     "shell.execute_reply": "2020-12-03T20:04:49.535159Z"
    },
    "papermill": {
     "duration": 3.04762,
     "end_time": "2020-12-03T20:04:49.535326",
     "exception": false,
     "start_time": "2020-12-03T20:04:46.487706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_sample(train_set_512[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:49.853712Z",
     "iopub.status.busy": "2020-12-03T20:04:49.852646Z",
     "iopub.status.idle": "2020-12-03T20:04:52.786621Z",
     "shell.execute_reply": "2020-12-03T20:04:52.787245Z"
    },
    "papermill": {
     "duration": 3.092384,
     "end_time": "2020-12-03T20:04:52.787401",
     "exception": false,
     "start_time": "2020-12-03T20:04:49.695017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_sample(train_set_512[25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.193136,
     "end_time": "2020-12-03T20:04:53.181110",
     "exception": false,
     "start_time": "2020-12-03T20:04:52.987974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transforms (Work in Progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:53.568717Z",
     "iopub.status.busy": "2020-12-03T20:04:53.567730Z",
     "iopub.status.idle": "2020-12-03T20:04:53.571092Z",
     "shell.execute_reply": "2020-12-03T20:04:53.570318Z"
    },
    "papermill": {
     "duration": 0.202388,
     "end_time": "2020-12-03T20:04:53.571220",
     "exception": false,
     "start_time": "2020-12-03T20:04:53.368832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        raster_diff, mask_diff = sample['raster_diff'], sample['mask_diff']\n",
    "        sample['raster_diff'] = torch.from_numpy(raster_diff)\n",
    "        sample['mask_diff'] = torch.from_numpy(mask_diff)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:53.962910Z",
     "iopub.status.busy": "2020-12-03T20:04:53.961749Z",
     "iopub.status.idle": "2020-12-03T20:04:53.965332Z",
     "shell.execute_reply": "2020-12-03T20:04:53.964580Z"
    },
    "papermill": {
     "duration": 0.204333,
     "end_time": "2020-12-03T20:04:53.965456",
     "exception": false,
     "start_time": "2020-12-03T20:04:53.761123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AsImage(object):\n",
    "    \"\"\"Convert shape of image from (Channels,Rows,Columns) to (Rows,Column,Channels).\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        raster_diff, mask_diff = sample['raster_diff'], sample['mask_diff']\n",
    "        sample['raster_diff'] = torch.from_numpy(raster_diff)\n",
    "        sample['mask_diff'] = torch.from_numpy(mask_diff)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:54.356017Z",
     "iopub.status.busy": "2020-12-03T20:04:54.355166Z",
     "iopub.status.idle": "2020-12-03T20:04:54.395367Z",
     "shell.execute_reply": "2020-12-03T20:04:54.394662Z"
    },
    "papermill": {
     "duration": 0.236745,
     "end_time": "2020-12-03T20:04:54.395502",
     "exception": false,
     "start_time": "2020-12-03T20:04:54.158757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.193175,
     "end_time": "2020-12-03T20:04:54.781361",
     "exception": false,
     "start_time": "2020-12-03T20:04:54.588186",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DataLoader (Work in Progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.194094,
     "end_time": "2020-12-03T20:04:55.170068",
     "exception": false,
     "start_time": "2020-12-03T20:04:54.975974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```\n",
    "A.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "A.Rotate(limit=(-360, 360), interpolation=4, border_mode=4,p=0),\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:55.562079Z",
     "iopub.status.busy": "2020-12-03T20:04:55.561126Z",
     "iopub.status.idle": "2020-12-03T20:04:55.564085Z",
     "shell.execute_reply": "2020-12-03T20:04:55.564634Z"
    },
    "papermill": {
     "duration": 0.201375,
     "end_time": "2020-12-03T20:04:55.564811",
     "exception": false,
     "start_time": "2020-12-03T20:04:55.363436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chip_dimension = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:55.957488Z",
     "iopub.status.busy": "2020-12-03T20:04:55.956613Z",
     "iopub.status.idle": "2020-12-03T20:04:55.960240Z",
     "shell.execute_reply": "2020-12-03T20:04:55.959463Z"
    },
    "papermill": {
     "duration": 0.204075,
     "end_time": "2020-12-03T20:04:55.960367",
     "exception": false,
     "start_time": "2020-12-03T20:04:55.756292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [\n",
    "        A.PadIfNeeded(min_height=chip_dimension,min_width=chip_dimension,value=0,p=1),\n",
    "        A.RandomRotate90(p=1.0),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:56.355591Z",
     "iopub.status.busy": "2020-12-03T20:04:56.354772Z",
     "iopub.status.idle": "2020-12-03T20:04:56.433540Z",
     "shell.execute_reply": "2020-12-03T20:04:56.432649Z"
    },
    "papermill": {
     "duration": 0.279912,
     "end_time": "2020-12-03T20:04:56.433671",
     "exception": false,
     "start_time": "2020-12-03T20:04:56.153759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set_64 = MultiTemporalSatelliteDataset(root_dir=root_dir,csv_file=csv_file,chip_dimension=chip_dimension,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:56.825227Z",
     "iopub.status.busy": "2020-12-03T20:04:56.824411Z",
     "iopub.status.idle": "2020-12-03T20:04:58.723978Z",
     "shell.execute_reply": "2020-12-03T20:04:58.724613Z"
    },
    "papermill": {
     "duration": 2.098912,
     "end_time": "2020-12-03T20:04:58.724774",
     "exception": false,
     "start_time": "2020-12-03T20:04:56.625862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_sample(train_set_64[328])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:04:59.140857Z",
     "iopub.status.busy": "2020-12-03T20:04:59.140087Z",
     "iopub.status.idle": "2020-12-03T20:05:00.951826Z",
     "shell.execute_reply": "2020-12-03T20:05:00.951249Z"
    },
    "papermill": {
     "duration": 2.019211,
     "end_time": "2020-12-03T20:05:00.951966",
     "exception": false,
     "start_time": "2020-12-03T20:04:58.932755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_sample(train_set_64[328])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:05:01.384899Z",
     "iopub.status.busy": "2020-12-03T20:05:01.383800Z",
     "iopub.status.idle": "2020-12-03T20:05:03.036084Z",
     "shell.execute_reply": "2020-12-03T20:05:03.035299Z"
    },
    "papermill": {
     "duration": 1.879642,
     "end_time": "2020-12-03T20:05:03.036216",
     "exception": false,
     "start_time": "2020-12-03T20:05:01.156574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_sample(train_set_64[328])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:05:03.446260Z",
     "iopub.status.busy": "2020-12-03T20:05:03.445060Z",
     "iopub.status.idle": "2020-12-03T20:05:03.448485Z",
     "shell.execute_reply": "2020-12-03T20:05:03.447872Z"
    },
    "papermill": {
     "duration": 0.205757,
     "end_time": "2020-12-03T20:05:03.448606",
     "exception": false,
     "start_time": "2020-12-03T20:05:03.242849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_set_64, batch_size=8,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:05:03.854518Z",
     "iopub.status.busy": "2020-12-03T20:05:03.853728Z",
     "iopub.status.idle": "2020-12-03T20:05:18.198591Z",
     "shell.execute_reply": "2020-12-03T20:05:18.197767Z"
    },
    "papermill": {
     "duration": 14.551527,
     "end_time": "2020-12-03T20:05:18.198719",
     "exception": false,
     "start_time": "2020-12-03T20:05:03.647192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:05:18.604883Z",
     "iopub.status.busy": "2020-12-03T20:05:18.603688Z",
     "iopub.status.idle": "2020-12-03T20:05:18.607977Z",
     "shell.execute_reply": "2020-12-03T20:05:18.607355Z"
    },
    "papermill": {
     "duration": 0.210557,
     "end_time": "2020-12-03T20:05:18.608101",
     "exception": false,
     "start_time": "2020-12-03T20:05:18.397544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch['raster_diff'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T20:05:19.015596Z",
     "iopub.status.busy": "2020-12-03T20:05:19.014766Z",
     "iopub.status.idle": "2020-12-03T20:05:19.047248Z",
     "shell.execute_reply": "2020-12-03T20:05:19.047848Z"
    },
    "papermill": {
     "duration": 0.240023,
     "end_time": "2020-12-03T20:05:19.048023",
     "exception": false,
     "start_time": "2020-12-03T20:05:18.808000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.199862,
     "end_time": "2020-12-03T20:05:19.449980",
     "exception": false,
     "start_time": "2020-12-03T20:05:19.250118",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sampler (Work in Progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.199361,
     "end_time": "2020-12-03T20:05:19.849459",
     "exception": false,
     "start_time": "2020-12-03T20:05:19.650098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Schedular (Work in Progress)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('earth')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "duration": 49.188392,
   "end_time": "2020-12-03T20:05:20.160056",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-03T20:04:30.971664",
   "version": "2.1.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "0482cfbd23fec52e9bb6e886bbc4c330bc05a0354edc96e1b8d7e0e01b9b55af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
